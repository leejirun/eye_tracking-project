{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras : 딥러닝 모델을 훈련시키거나 모델을 로드하여 분류, 예측하는 프레임워크\n",
    "#keras중 cnn: 딥러닝 알고리즘 중 이미지를 분류하고 인식하는데 효율적인 알고리즘 중 하나\n",
    "#numpy : 행렬 연산을 가능하게 해주는 파이썬 라이브러리\n",
    "#matplotlib : 수학적인 그래프를 그려주는 라이브러리 \n",
    "#cnn개념"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Activation, Conv2D, Flatten, Dense, MaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "왼쪽\n",
      "(2586, 26, 34, 1) (2586, 1)\n",
      "(288, 26, 34, 1) (288, 1)\n",
      "오른쪽\n",
      "(2586, 26, 34, 1) (2586, 1)\n",
      "(288, 26, 34, 1) (288, 1)\n"
     ]
    }
   ],
   "source": [
    "#왼쪽\n",
    "left_x_train = np.load('datas/np_data/left_x_train.npy').astype(np.float32)\n",
    "left_y_train = np.load('datas/np_data/left_y_train.npy').astype(np.float32)\n",
    "left_x_val = np.load('datas/np_data/left_x_val.npy').astype(np.float32)\n",
    "left_y_val = np.load('datas/np_data/left_y_val.npy').astype(np.float32)\n",
    "\n",
    "#오른쪽\n",
    "right_x_train = np.load('datas/np_data/right_x_train.npy').astype(np.float32)\n",
    "right_y_train = np.load('datas/np_data/right_y_train.npy').astype(np.float32)\n",
    "right_x_val = np.load('datas/np_data/right_x_val.npy').astype(np.float32)\n",
    "right_y_val = np.load('datas/np_data/right_y_val.npy').astype(np.float32) # astype(타입형태) 원하는 형태의 타입으로 변경(int, float)\n",
    "\n",
    "print(\"왼쪽\")\n",
    "print(left_x_train.shape, left_y_train.shape)\n",
    "print(left_x_val.shape, left_y_val.shape)\n",
    "\n",
    "print(\"오른쪽\")\n",
    "print(right_x_train.shape, right_y_train.shape)\n",
    "print(right_x_val.shape, right_y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd4a543b6a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(left_x_train[105], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_y_train[105] #y는 라벨링 데이터 0(감은눈) 또는 1(뜬눈)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7ae9f48eb0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.title(str(left_y_train[0]))\n",
    "plt.imshow(left_x_train[0].reshape((26, 34, 1)), cmap='gray')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title(str(left_y_val[4]))\n",
    "plt.imshow(left_x_val[4].reshape((26, 34, 1)), cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation(데이터 증가)->훈련용 데이터를 증가시키고 성능을 향상시키기 위해 하는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "왼쪽\n",
      "오른쪽\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(#가상의 이미지 데이터를 생성하는 것 why 훈련 성능 향상, 너무 훈련용데이터에만 적응하는 과적합을 막기 위해서도\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2\n",
    ")\n",
    "#과적합 : 과도하게 적합한 것을 의미, 너무 훈련을 잘해서 정해진 값만 정확하게 판단하려고 파라미터 값들을 맞추는 것.\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255) #검증용은 굳이 변형이 필요없이 생성만\n",
    "\n",
    "print(\"왼쪽\")\n",
    "left_train_generator = train_datagen.flow(\n",
    "    x=left_x_train, y=left_y_train,\n",
    "    batch_size=32, # 한 횟수의 훈련 및 검증에 사용될 데이터 량(32개씩)\n",
    "    shuffle=True # 순서를 섞는것\n",
    ")\n",
    "\n",
    "left_val_generator = val_datagen.flow(\n",
    "    x=left_x_val, y=left_y_val,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"오른쪽\")\n",
    "right_train_generator = train_datagen.flow(\n",
    "    x=right_x_train, y=right_y_train,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "right_val_generator = val_datagen.flow(\n",
    "    x=right_x_val, y=right_y_val,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model cnn모델은 인풋레이어(인풋 정보 정의), 히든레이어(conv갯수에 따라 몇층인지), 아웃풋레이어(3차원데이터를 분류하기 편한 1차원으로 변경 및 활성화함수로 분류)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 26, 34, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 26, 34, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 13, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 13, 17, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 6, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 6, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 3, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               786944    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 880,129\n",
      "Trainable params: 880,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"functional_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 26, 34, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 26, 34, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 13, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 13, 17, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 6, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 6, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 3, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               786944    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 880,129\n",
      "Trainable params: 880,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#왼쪽, 오른쪽 테이블 두개\n",
    "inputs = Input(shape=(26, 34, 1)) #input층\n",
    "\n",
    "net = Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(inputs) \n",
    "#convolutional 층을 쌓아 filter 크기(3*3), strides filter가 몇칸씩 이동하는지, padding same은 공간 정보 유지를 원한다.\n",
    "#, activation 활성화함수 relu 음수 0, 양수는 그래도 표현\n",
    "# ㄷㄷㄷㄷㄷ\n",
    "# ㄷㅌㅌㅌㄷ    \n",
    "# ㄷㅌㅌㅌㄷ -> 5*5 3*3\n",
    "# ㄷㅌㅌㅌㄷ\n",
    "# ㄷㄷㄷㄷㄷ\n",
    "net = MaxPooling2D(pool_size=2)(net) #polling층 가장 자극이 강한 것만 다시 재추출하는 maxpolling, poll_size = 2\n",
    "# 1  19   ---> 55\n",
    "# 55 34\n",
    "\n",
    "#1층 끝 보통 conv와 polling은 1개의 층으로 침\n",
    "\n",
    "net = Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu')(net)\n",
    "net = MaxPooling2D(pool_size=2)(net)\n",
    "#2층 끝\n",
    "\n",
    "net = Conv2D(128, kernel_size=3, strides=1, padding='same', activation='relu')(net)\n",
    "net = MaxPooling2D(pool_size=2)(net)\n",
    "#3층 끝\n",
    "\n",
    "net = Flatten()(net) # 3차원데이터를 1차원으로 변경\n",
    "\n",
    "net = Dense(512)(net)\n",
    "net = Activation('relu')(net) #relu 음수면 0 양수면 1로 변경하는 활성화함수\n",
    "net = Dense(1)(net)\n",
    "outputs = Activation('sigmoid')(net) #결과를 도출하는 층, 활성화함수 sigmoid 사용 why 이진분류 if 다중분류 softmax 사용\n",
    "\n",
    "left_model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "left_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "left_model.summary()\n",
    "\n",
    "right_model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "right_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "right_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 00001: val_acc improved from -inf to 0.99306, saving model to datas/models/left_eye.h5\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0295 - val_acc: 0.9931\n",
      "Epoch 2/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0064 - acc: 0.9981\n",
      "Epoch 00002: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 5s 67ms/step - loss: 0.0064 - acc: 0.9981 - val_loss: 0.0281 - val_acc: 0.9931\n",
      "Epoch 3/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0046 - acc: 0.9988\n",
      "Epoch 00003: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 6s 77ms/step - loss: 0.0046 - acc: 0.9988 - val_loss: 0.0282 - val_acc: 0.9931\n",
      "Epoch 4/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0033 - acc: 0.9996\n",
      "Epoch 00004: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.0033 - acc: 0.9996 - val_loss: 0.0281 - val_acc: 0.9931\n",
      "Epoch 5/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0031 - acc: 0.9988\n",
      "Epoch 00005: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 6s 77ms/step - loss: 0.0031 - acc: 0.9988 - val_loss: 0.0286 - val_acc: 0.9931\n",
      "Epoch 6/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0049 - acc: 0.9977\n",
      "Epoch 00006: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 7s 84ms/step - loss: 0.0049 - acc: 0.9977 - val_loss: 0.0301 - val_acc: 0.9931\n",
      "Epoch 7/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9984\n",
      "Epoch 00007: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 6s 72ms/step - loss: 0.0050 - acc: 0.9985 - val_loss: 0.0306 - val_acc: 0.9931\n",
      "Epoch 8/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0054 - acc: 0.9981\n",
      "Epoch 00008: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 8s 94ms/step - loss: 0.0054 - acc: 0.9981 - val_loss: 0.0314 - val_acc: 0.9931\n",
      "Epoch 9/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0064 - acc: 0.9985\n",
      "Epoch 00009: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 7s 85ms/step - loss: 0.0064 - acc: 0.9985 - val_loss: 0.0298 - val_acc: 0.9931\n",
      "Epoch 10/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0048 - acc: 0.9981\n",
      "Epoch 00010: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 7s 85ms/step - loss: 0.0048 - acc: 0.9981 - val_loss: 0.0286 - val_acc: 0.9931\n",
      "Epoch 11/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0034 - acc: 0.9992\n",
      "Epoch 00011: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 7s 83ms/step - loss: 0.0034 - acc: 0.9992 - val_loss: 0.0286 - val_acc: 0.9931\n",
      "Epoch 12/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0023 - acc: 0.9996\n",
      "Epoch 00012: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 6s 79ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 0.0291 - val_acc: 0.9931\n",
      "Epoch 13/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0040 - acc: 0.9988\n",
      "Epoch 00013: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 6s 78ms/step - loss: 0.0040 - acc: 0.9988 - val_loss: 0.0294 - val_acc: 0.9931\n",
      "Epoch 14/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0045 - acc: 0.9985\n",
      "Epoch 00014: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 6s 77ms/step - loss: 0.0045 - acc: 0.9985 - val_loss: 0.0290 - val_acc: 0.9931\n",
      "Epoch 15/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0043 - acc: 0.9981\n",
      "Epoch 00015: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 6s 79ms/step - loss: 0.0043 - acc: 0.9981 - val_loss: 0.0296 - val_acc: 0.9931\n",
      "Epoch 16/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0058 - acc: 0.9981\n",
      "Epoch 00016: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 6s 77ms/step - loss: 0.0058 - acc: 0.9981 - val_loss: 0.0298 - val_acc: 0.9931\n",
      "Epoch 17/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0055 - acc: 0.9985\n",
      "Epoch 00017: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 6s 76ms/step - loss: 0.0055 - acc: 0.9985 - val_loss: 0.0308 - val_acc: 0.9931\n",
      "Epoch 18/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0030 - acc: 0.9988\n",
      "Epoch 00018: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 6s 77ms/step - loss: 0.0030 - acc: 0.9988 - val_loss: 0.0304 - val_acc: 0.9931\n",
      "Epoch 19/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0043 - acc: 0.9981\n",
      "Epoch 00019: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 6s 77ms/step - loss: 0.0043 - acc: 0.9981 - val_loss: 0.0295 - val_acc: 0.9931\n",
      "Epoch 20/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0051 - acc: 0.9985\n",
      "Epoch 00020: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 6s 75ms/step - loss: 0.0051 - acc: 0.9985 - val_loss: 0.0312 - val_acc: 0.9931\n",
      "Epoch 21/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0059 - acc: 0.9977\n",
      "Epoch 00021: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 6s 78ms/step - loss: 0.0059 - acc: 0.9977 - val_loss: 0.0311 - val_acc: 0.9931\n",
      "Epoch 22/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0034 - acc: 0.9985\n",
      "Epoch 00022: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 6s 78ms/step - loss: 0.0034 - acc: 0.9985 - val_loss: 0.0315 - val_acc: 0.9931\n",
      "Epoch 23/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0026 - acc: 0.9996\n",
      "Epoch 00023: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 6s 78ms/step - loss: 0.0026 - acc: 0.9996 - val_loss: 0.0301 - val_acc: 0.9931\n",
      "Epoch 24/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0038 - acc: 0.9992\n",
      "Epoch 00024: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 7s 81ms/step - loss: 0.0038 - acc: 0.9992 - val_loss: 0.0309 - val_acc: 0.9931\n",
      "Epoch 25/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0046 - acc: 0.9988\n",
      "Epoch 00025: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 5s 58ms/step - loss: 0.0046 - acc: 0.9988 - val_loss: 0.0308 - val_acc: 0.9931\n",
      "Epoch 26/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0051 - acc: 0.9985\n",
      "Epoch 00026: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 51ms/step - loss: 0.0051 - acc: 0.9985 - val_loss: 0.0317 - val_acc: 0.9931\n",
      "Epoch 27/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9977\n",
      "Epoch 00027: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 46ms/step - loss: 0.0041 - acc: 0.9977 - val_loss: 0.0310 - val_acc: 0.9931\n",
      "Epoch 28/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0034 - acc: 0.9988\n",
      "Epoch 00028: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 46ms/step - loss: 0.0034 - acc: 0.9988 - val_loss: 0.0306 - val_acc: 0.9931\n",
      "Epoch 29/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0028 - acc: 0.9992\n",
      "Epoch 00029: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 46ms/step - loss: 0.0028 - acc: 0.9992 - val_loss: 0.0297 - val_acc: 0.9931\n",
      "Epoch 30/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0059 - acc: 0.9977\n",
      "Epoch 00030: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 47ms/step - loss: 0.0059 - acc: 0.9977 - val_loss: 0.0309 - val_acc: 0.9931\n",
      "Epoch 31/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9988\n",
      "Epoch 00031: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 45ms/step - loss: 0.0046 - acc: 0.9988 - val_loss: 0.0315 - val_acc: 0.9931\n",
      "Epoch 32/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9992\n",
      "Epoch 00032: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 45ms/step - loss: 0.0035 - acc: 0.9992 - val_loss: 0.0301 - val_acc: 0.9931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9992\n",
      "Epoch 00033: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 46ms/step - loss: 0.0036 - acc: 0.9992 - val_loss: 0.0303 - val_acc: 0.9931\n",
      "Epoch 34/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9988\n",
      "Epoch 00034: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 44ms/step - loss: 0.0035 - acc: 0.9988 - val_loss: 0.0315 - val_acc: 0.9931\n",
      "Epoch 35/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0059 - acc: 0.9977\n",
      "Epoch 00035: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 45ms/step - loss: 0.0059 - acc: 0.9977 - val_loss: 0.0309 - val_acc: 0.9931\n",
      "Epoch 36/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9992\n",
      "Epoch 00036: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 47ms/step - loss: 0.0043 - acc: 0.9992 - val_loss: 0.0317 - val_acc: 0.9931\n",
      "Epoch 37/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0035 - acc: 0.9992\n",
      "Epoch 00037: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 44ms/step - loss: 0.0035 - acc: 0.9992 - val_loss: 0.0301 - val_acc: 0.9931\n",
      "Epoch 38/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0056 - acc: 0.9981\n",
      "Epoch 00038: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 46ms/step - loss: 0.0056 - acc: 0.9981 - val_loss: 0.0301 - val_acc: 0.9931\n",
      "Epoch 39/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0053 - acc: 0.9981\n",
      "Epoch 00039: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 45ms/step - loss: 0.0053 - acc: 0.9981 - val_loss: 0.0293 - val_acc: 0.9931\n",
      "Epoch 40/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0037 - acc: 0.9985\n",
      "Epoch 00040: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 47ms/step - loss: 0.0037 - acc: 0.9985 - val_loss: 0.0310 - val_acc: 0.9931\n",
      "Epoch 41/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9992\n",
      "Epoch 00041: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 45ms/step - loss: 0.0030 - acc: 0.9992 - val_loss: 0.0313 - val_acc: 0.9931\n",
      "Epoch 42/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0043 - acc: 0.9981\n",
      "Epoch 00042: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 47ms/step - loss: 0.0043 - acc: 0.9981 - val_loss: 0.0314 - val_acc: 0.9931\n",
      "Epoch 43/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9969\n",
      "Epoch 00043: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 46ms/step - loss: 0.0063 - acc: 0.9969 - val_loss: 0.0301 - val_acc: 0.9931\n",
      "Epoch 44/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9977\n",
      "Epoch 00044: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 48ms/step - loss: 0.0071 - acc: 0.9977 - val_loss: 0.0296 - val_acc: 0.9931\n",
      "Epoch 45/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9992\n",
      "Epoch 00045: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 46ms/step - loss: 0.0032 - acc: 0.9992 - val_loss: 0.0294 - val_acc: 0.9931\n",
      "Epoch 46/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0028 - acc: 0.9988\n",
      "Epoch 00046: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 45ms/step - loss: 0.0028 - acc: 0.9988 - val_loss: 0.0317 - val_acc: 0.9931\n",
      "Epoch 47/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0025 - acc: 0.9996\n",
      "Epoch 00047: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 47ms/step - loss: 0.0025 - acc: 0.9996 - val_loss: 0.0323 - val_acc: 0.9931\n",
      "Epoch 48/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9992\n",
      "Epoch 00048: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 47ms/step - loss: 0.0053 - acc: 0.9992 - val_loss: 0.0328 - val_acc: 0.9931\n",
      "Epoch 49/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0041 - acc: 0.9977\n",
      "Epoch 00049: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 45ms/step - loss: 0.0041 - acc: 0.9977 - val_loss: 0.0313 - val_acc: 0.9931\n",
      "Epoch 50/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0035 - acc: 0.9996\n",
      "Epoch 00050: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 47ms/step - loss: 0.0035 - acc: 0.9996 - val_loss: 0.0296 - val_acc: 0.9931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7ae85531c0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    left_train_generator, epochs=50, validation_data=left_val_generator,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint('datas/models/left_eye.h5', monitor='val_acc', save_best_only=True, mode='max', verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=10, verbose=1, mode='auto', min_lr=1e-05)\n",
    "    ]\n",
    ")\n",
    "\n",
    "#epochs 훈련 루틴 횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0741 - acc: 0.9799\n",
      "Epoch 00001: val_acc improved from -inf to 0.98958, saving model to datas/models/right_eye.h5\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.0741 - acc: 0.9799 - val_loss: 0.0417 - val_acc: 0.9896\n",
      "Epoch 2/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0597 - acc: 0.9841\n",
      "Epoch 00002: val_acc did not improve from 0.98958\n",
      "81/81 [==============================] - 6s 71ms/step - loss: 0.0597 - acc: 0.9841 - val_loss: 0.0411 - val_acc: 0.9896\n",
      "Epoch 3/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0666 - acc: 0.9814\n",
      "Epoch 00003: val_acc did not improve from 0.98958\n",
      "81/81 [==============================] - 5s 66ms/step - loss: 0.0666 - acc: 0.9814 - val_loss: 0.0368 - val_acc: 0.9896\n",
      "Epoch 4/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0575 - acc: 0.9845\n",
      "Epoch 00004: val_acc did not improve from 0.98958\n",
      "81/81 [==============================] - 6s 70ms/step - loss: 0.0575 - acc: 0.9845 - val_loss: 0.0345 - val_acc: 0.9896\n",
      "Epoch 5/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0539 - acc: 0.9869\n",
      "Epoch 00005: val_acc did not improve from 0.98958\n",
      "81/81 [==============================] - 6s 75ms/step - loss: 0.0539 - acc: 0.9869 - val_loss: 0.0327 - val_acc: 0.9896\n",
      "Epoch 6/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0500 - acc: 0.9845\n",
      "Epoch 00006: val_acc did not improve from 0.98958\n",
      "81/81 [==============================] - 6s 75ms/step - loss: 0.0500 - acc: 0.9845 - val_loss: 0.0320 - val_acc: 0.9896\n",
      "Epoch 7/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0563 - acc: 0.9857\n",
      "Epoch 00007: val_acc improved from 0.98958 to 0.99306, saving model to datas/models/right_eye.h5\n",
      "81/81 [==============================] - 6s 76ms/step - loss: 0.0563 - acc: 0.9857 - val_loss: 0.0299 - val_acc: 0.9931\n",
      "Epoch 8/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0528 - acc: 0.9853\n",
      "Epoch 00008: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 6s 74ms/step - loss: 0.0528 - acc: 0.9853 - val_loss: 0.0332 - val_acc: 0.9896\n",
      "Epoch 9/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0491 - acc: 0.9853\n",
      "Epoch 00009: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 6s 75ms/step - loss: 0.0491 - acc: 0.9853 - val_loss: 0.0295 - val_acc: 0.9896\n",
      "Epoch 10/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0512 - acc: 0.9884\n",
      "Epoch 00010: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 6s 74ms/step - loss: 0.0512 - acc: 0.9884 - val_loss: 0.0323 - val_acc: 0.9896\n",
      "Epoch 11/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0458 - acc: 0.9884\n",
      "Epoch 00011: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 6s 76ms/step - loss: 0.0458 - acc: 0.9884 - val_loss: 0.0273 - val_acc: 0.9896\n",
      "Epoch 12/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0448 - acc: 0.9865\n",
      "Epoch 00012: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 6s 74ms/step - loss: 0.0448 - acc: 0.9865 - val_loss: 0.0279 - val_acc: 0.9896\n",
      "Epoch 13/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0476 - acc: 0.9872\n",
      "Epoch 00013: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 6s 75ms/step - loss: 0.0476 - acc: 0.9872 - val_loss: 0.0300 - val_acc: 0.9896\n",
      "Epoch 14/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0456 - acc: 0.9876\n",
      "Epoch 00014: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 6s 74ms/step - loss: 0.0456 - acc: 0.9876 - val_loss: 0.0295 - val_acc: 0.9896\n",
      "Epoch 15/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0496 - acc: 0.9884\n",
      "Epoch 00015: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 6s 76ms/step - loss: 0.0496 - acc: 0.9884 - val_loss: 0.0264 - val_acc: 0.9896\n",
      "Epoch 16/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0431 - acc: 0.9903\n",
      "Epoch 00016: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 6s 76ms/step - loss: 0.0431 - acc: 0.9903 - val_loss: 0.0264 - val_acc: 0.9896\n",
      "Epoch 17/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9898\n",
      "Epoch 00017: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 6s 76ms/step - loss: 0.0412 - acc: 0.9896 - val_loss: 0.0298 - val_acc: 0.9896\n",
      "Epoch 18/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0417 - acc: 0.9865\n",
      "Epoch 00018: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 6s 75ms/step - loss: 0.0417 - acc: 0.9865 - val_loss: 0.0284 - val_acc: 0.9896\n",
      "Epoch 19/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0447 - acc: 0.9869\n",
      "Epoch 00019: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 6s 76ms/step - loss: 0.0447 - acc: 0.9869 - val_loss: 0.0277 - val_acc: 0.9896\n",
      "Epoch 20/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0450 - acc: 0.9857\n",
      "Epoch 00020: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 6s 74ms/step - loss: 0.0450 - acc: 0.9857 - val_loss: 0.0270 - val_acc: 0.9896\n",
      "Epoch 21/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0467 - acc: 0.9884\n",
      "Epoch 00021: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 6s 77ms/step - loss: 0.0467 - acc: 0.9884 - val_loss: 0.0248 - val_acc: 0.9896\n",
      "Epoch 22/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0459 - acc: 0.9880\n",
      "Epoch 00022: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 6s 75ms/step - loss: 0.0459 - acc: 0.9880 - val_loss: 0.0217 - val_acc: 0.9931\n",
      "Epoch 23/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0392 - acc: 0.9896\n",
      "Epoch 00023: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 6s 78ms/step - loss: 0.0392 - acc: 0.9896 - val_loss: 0.0215 - val_acc: 0.9931\n",
      "Epoch 24/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9894\n",
      "Epoch 00024: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 6s 75ms/step - loss: 0.0434 - acc: 0.9896 - val_loss: 0.0235 - val_acc: 0.9896\n",
      "Epoch 25/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9890\n",
      "Epoch 00025: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 48ms/step - loss: 0.0391 - acc: 0.9892 - val_loss: 0.0217 - val_acc: 0.9931\n",
      "Epoch 26/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0400 - acc: 0.9857\n",
      "Epoch 00026: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 46ms/step - loss: 0.0400 - acc: 0.9857 - val_loss: 0.0212 - val_acc: 0.9931\n",
      "Epoch 27/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9906\n",
      "Epoch 00027: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 47ms/step - loss: 0.0332 - acc: 0.9903 - val_loss: 0.0204 - val_acc: 0.9931\n",
      "Epoch 28/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9902\n",
      "Epoch 00028: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 45ms/step - loss: 0.0395 - acc: 0.9899 - val_loss: 0.0233 - val_acc: 0.9896\n",
      "Epoch 29/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.9886\n",
      "Epoch 00029: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 47ms/step - loss: 0.0441 - acc: 0.9884 - val_loss: 0.0212 - val_acc: 0.9896\n",
      "Epoch 30/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0418 - acc: 0.9880\n",
      "Epoch 00030: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 45ms/step - loss: 0.0418 - acc: 0.9880 - val_loss: 0.0208 - val_acc: 0.9931\n",
      "Epoch 31/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9898\n",
      "Epoch 00031: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 47ms/step - loss: 0.0388 - acc: 0.9899 - val_loss: 0.0215 - val_acc: 0.9896\n",
      "Epoch 32/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0370 - acc: 0.9903\n",
      "Epoch 00032: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 46ms/step - loss: 0.0370 - acc: 0.9903 - val_loss: 0.0216 - val_acc: 0.9931\n",
      "Epoch 33/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0353 - acc: 0.9899\n",
      "Epoch 00033: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 4s 48ms/step - loss: 0.0353 - acc: 0.9899 - val_loss: 0.0224 - val_acc: 0.9896\n",
      "Epoch 34/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0348 - acc: 0.9888\n",
      "Epoch 00034: val_acc improved from 0.99306 to 0.99653, saving model to datas/models/right_eye.h5\n",
      "81/81 [==============================] - 4s 45ms/step - loss: 0.0348 - acc: 0.9888 - val_loss: 0.0187 - val_acc: 0.9965\n",
      "Epoch 35/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9918\n",
      "Epoch 00035: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 4s 48ms/step - loss: 0.0332 - acc: 0.9919 - val_loss: 0.0196 - val_acc: 0.9965\n",
      "Epoch 36/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9867\n",
      "Epoch 00036: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 4s 48ms/step - loss: 0.0389 - acc: 0.9865 - val_loss: 0.0182 - val_acc: 0.9965\n",
      "Epoch 37/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9898\n",
      "Epoch 00037: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 4s 45ms/step - loss: 0.0320 - acc: 0.9899 - val_loss: 0.0200 - val_acc: 0.9965\n",
      "Epoch 38/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0356 - acc: 0.9880\n",
      "Epoch 00038: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 4s 46ms/step - loss: 0.0356 - acc: 0.9880 - val_loss: 0.0192 - val_acc: 0.9965\n",
      "Epoch 39/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0293 - acc: 0.9907\n",
      "Epoch 00039: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 4s 47ms/step - loss: 0.0293 - acc: 0.9907 - val_loss: 0.0169 - val_acc: 0.9965\n",
      "Epoch 40/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9922\n",
      "Epoch 00040: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 4s 47ms/step - loss: 0.0313 - acc: 0.9923 - val_loss: 0.0174 - val_acc: 0.9965\n",
      "Epoch 41/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9914\n",
      "Epoch 00041: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 4s 47ms/step - loss: 0.0305 - acc: 0.9911 - val_loss: 0.0197 - val_acc: 0.9965\n",
      "Epoch 42/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0344 - acc: 0.9923\n",
      "Epoch 00042: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 4s 45ms/step - loss: 0.0344 - acc: 0.9923 - val_loss: 0.0183 - val_acc: 0.9965\n",
      "Epoch 43/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9914\n",
      "Epoch 00043: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 4s 48ms/step - loss: 0.0336 - acc: 0.9915 - val_loss: 0.0200 - val_acc: 0.9965\n",
      "Epoch 44/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9930\n",
      "Epoch 00044: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 4s 45ms/step - loss: 0.0317 - acc: 0.9930 - val_loss: 0.0182 - val_acc: 0.9965\n",
      "Epoch 45/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0270 - acc: 0.9938\n",
      "Epoch 00045: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 4s 45ms/step - loss: 0.0270 - acc: 0.9938 - val_loss: 0.0189 - val_acc: 0.9965\n",
      "Epoch 46/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0328 - acc: 0.9907\n",
      "Epoch 00046: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 4s 45ms/step - loss: 0.0328 - acc: 0.9907 - val_loss: 0.0188 - val_acc: 0.9965\n",
      "Epoch 47/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0296 - acc: 0.9911\n",
      "Epoch 00047: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 4s 47ms/step - loss: 0.0296 - acc: 0.9911 - val_loss: 0.0201 - val_acc: 0.9965\n",
      "Epoch 48/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9914\n",
      "Epoch 00048: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 4s 47ms/step - loss: 0.0305 - acc: 0.9911 - val_loss: 0.0212 - val_acc: 0.9965\n",
      "Epoch 49/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9906\n",
      "Epoch 00049: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 4s 47ms/step - loss: 0.0346 - acc: 0.9907 - val_loss: 0.0199 - val_acc: 0.9965\n",
      "Epoch 50/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9922\n",
      "Epoch 00050: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 4s 46ms/step - loss: 0.0302 - acc: 0.9923 - val_loss: 0.0202 - val_acc: 0.9965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7ae0446c70>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    right_train_generator, epochs=50, validation_data=right_val_generator,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint('datas/models/right_eye.h5', monitor='val_acc', save_best_only=True, mode='max', verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=10, verbose=1, mode='auto', min_lr=1e-05)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 0.9930555555555556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "model = load_model('datas/models/left_eye.h5')\n",
    "\n",
    "y_pred = model.predict(left_x_val/255.)\n",
    "y_pred_logical = (y_pred > 0.5).astype(np.int)\n",
    "\n",
    "print ('test acc: %s' % accuracy_score(left_y_val, y_pred_logical))\n",
    "cm = confusion_matrix(left_y_val, y_pred_logical)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 0.9965277777777778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_model('datas/models/right_eye.h5')\n",
    "\n",
    "y_pred = model.predict(right_x_val/255.)\n",
    "y_pred_logical = (y_pred > 0.5).astype(np.int)\n",
    "\n",
    "print ('test acc: %s' % accuracy_score(right_y_val, y_pred_logical))\n",
    "cm = confusion_matrix(right_y_val, y_pred_logical)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
